{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothing BreakfastClub "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image \n",
    "import glob, os\n",
    "\n",
    "# get data\n",
    "sessions = [\"ses-1\", \"ses-2\"]\n",
    "data_path = \"/projects/niblab/bids_projects/Experiments/BreakfastClub/derivatives\"\n",
    "SUBS = sorted(glob.glob(os.path.join(data_path, \"sub-*\")))\n",
    "for sub_path in SUBS:\n",
    "    for ses in sessions:\n",
    "        ## path exists == session exists, continue with conversion\n",
    "        ## get functional images \n",
    "        FUNCS = glob.glob(os.path.join(sub_path, \"func\", \"*_brain.nii.gz\"))\n",
    "        for epi_file in FUNCS:\n",
    "            filename = epi_file.split(\"/\")[-1]\n",
    "            subID = filename.split(\"_\")[0]\n",
    "            task = filename.split(\"_\")[2]\n",
    "            ses = filename.split(\"_\")[1]\n",
    "            new_filename = os.path.join(sub_path, \"func/%s_%s_%s_smoothed.nii.gz\"%(subID, ses, task))\n",
    "            print(new_filename)\n",
    "            mean_func = image.mean_img(epi_file)\n",
    "            smoothed_img = image.smooth_img(mean_func, fwhm=5)\n",
    "            smoothed_img.to_filename(new_filename)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import glob\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import os\n",
    "import subprocess\n",
    "import datetime\n",
    "import shutil\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skull_strip(sub, func_path):\n",
    "    print(\">>>>---> starting bet on \", sub )\n",
    "    try:\n",
    "        for nifti in glob.glob(os.path.join(func_path, '%s/func/*ses-2*desc-preproc_bold.nii.gz'%sub)):\n",
    "            # make our variables\n",
    "            filename = nifti.split(\"/\")[-1].split(\".\")[0]\n",
    "            bet_name=filename+'_brain'\n",
    "            bet_output = os.path.join(func_path,\"%s/func\"%sub, bet_name)\n",
    "            print(\"SKULL STRIP, NEW FILE TO BE MADE: \", bet_name)\n",
    "            if os.path.exists(bet_output + '.nii'):\n",
    "                print(bet_output + ' exists, skipping \\n')\n",
    "            else:\n",
    "                print(\"Running bet on \", nifti)\n",
    "                bet_cmd=(\"bet %s %s -F -m -f %s\"%(nifti, bet_output, \"0.6\"))\n",
    "                print(\">>>-----> BET COMMAND:\", bet_cmd)\n",
    "                os.system(bet_cmd)\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "deriv_path= \"/projects/niblab/bids_projects/Experiments/BreakfastClub/derivatives\"\n",
    "subjects = sorted(glob.glob(os.path.join(deriv_path, \"sub-*\")))\n",
    "\n",
    "    \n",
    "for path in subjects:\n",
    "    sub_id = path.split(\"/\")[-1]\n",
    "    skull_strip(sub_id,deriv_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fd_check(sub, outfile, out_bad_bold_list, derivatives_dir):\n",
    "    func_path = os.path.join(derivatives_dir, sub, \"func\")\n",
    "    print(\">>>>---> Starting motion correction on \", sub)\n",
    "    motion_assessment_path=os.path.join(derivatives_dir, sub, 'func','motion_assessment')\n",
    "    if not os.path.exists(motion_assessment_path):\n",
    "        os.makedirs(motion_assessment_path)\n",
    "    try:\n",
    "# iterate over nifti file\n",
    "        for nifti in glob.glob(os.path.join(func_path, '*_brain.nii*')):\n",
    "            filename=nifti.split('.')[0]\n",
    "            file = filename.split(\"/\")[-1]\n",
    "            outlier_path = \"%s/%s_outlier_output.txt\"%(motion_assessment_path, file)\n",
    "            plot_path = \"%s/%s_fd_plot\"%(motion_assessment_path, file)\n",
    "            confound_path = \"%s/%s_confound.txt\"%(motion_assessment_path, file)\n",
    "            #need to get identifier for tasks and runs --rn for bevel, need to specify for versatility \n",
    "            # set comparison param\n",
    "            nvols_cmd=\"fslnvols \" + nifti\n",
    "            volume = subprocess.check_output(nvols_cmd, shell=True, encoding=\"utf-8\")\n",
    "            volume = volume.strip()\n",
    "            comparator = int(volume) *.25\n",
    "            ## RUN 'fsl_motion_outliers' TO RETRIEVE MOTION CORRECTION ANALYSIS\n",
    "            outlier_cmd = \"fsl_motion_outliers -i %s  -o %s --fd --thresh=%s -p %s -v > %s\"%(filename, confound_path, \"0.9\", plot_path, outlier_path)\n",
    "            print(\">>-->  RUNNING FSL MOTION OUTLIERS \")\n",
    "            print(\"COMMAND NVOLS: \", nvols_cmd)\n",
    "            print(\"OUTLIER CMD: \", outlier_cmd)\n",
    "            os.system(outlier_cmd)\n",
    "        ## EXAMINE OUTLIER FILE AND GRAB RELEVANT DATA \n",
    "            with open(outlier_path, 'r') as f:\n",
    "                lines=f.readlines()\n",
    "                statsA = lines[1].strip(\"\\n\") #maskmean\n",
    "                statsB = lines[3].strip(\"\\n\") #metric range\n",
    "                statsC = lines[4].strip(\"\\n\") #outliers found\n",
    "                if int(statsC.split(\" \")[1])  > 0:\n",
    "                    statsD = lines[6].strip(\"\\n\") #spikes found\n",
    "                else:\n",
    "                    statsD = \"\\n\"\n",
    "            f.close()\n",
    "        ## GRAB MOTION CORRECTION PLOT AND WRITE PLOT & INFO TO HTML\n",
    "            plotz=plot_path+\".png\"\n",
    "            FILEINFO=\"\"\"<p><font size=6> <b>{CURR_FILENAME} </b></font><br>\"\"\"\n",
    "            CURR_FILEINFO = FILEINFO.format(CURR_FILENAME=file)\n",
    "            outfile.write(CURR_FILEINFO)\n",
    "            INFO=\"\"\"<p><font size=6>{A} <br><b>{B}<b><br>{C}<br><b>{D}</b><br><br>\"\"\"\n",
    "            CURR_INFO= INFO.format(A=statsA, B=statsB, C=statsC, D=statsD)\n",
    "            outfile.write(CURR_INFO)\n",
    "            PLOT=\"\"\"<IMG SRC=\\\"{PLOTPATH}\\\" WIDTH=100%><br><br>\"\"\"\n",
    "            CURR_PLOT = PLOT.format(PLOTPATH=plotz)\n",
    "            outfile.write(CURR_PLOT)\n",
    "            print(\">>>>----> ADDING PLOT TO HTML\")\n",
    "                ## ADD FILE FOR GOOD SUBJECT \n",
    "        # --sometimes you have a great subject who didn't move\n",
    "            if os.path.isfile(confound_path)==False:\n",
    "                os.system(\"touch %s\"%confound_path)\n",
    "                \n",
    "        ## CHECK FOR BAD SUBJECTS: ABOVE OUR THRESHOLD\n",
    "        # how many columns are there = how many 'bad' points\n",
    "            check = subprocess.check_output(\"grep -o 1 %s | wc -l\"%(confound_path), shell=True)\n",
    "            num_scrub = [int(s) for s in check.split() if s.isdigit()]\n",
    "            print(\"NUM SCRUB: \", str(num_scrub[0]), \"\\n\")\n",
    "            if num_scrub[0] > comparator: #if the number in check is greater than num_scrub then we don't want it\n",
    "                with open(out_bad_bold_list, \"a\") as myfile: #making a file that lists all the bad ones\n",
    "                    myfile.write(\"%s/%s\\n\"%(derivatives_dir, file))\n",
    "                    print(\"wrote bad file\")\n",
    "                myfile.close()\n",
    "    except FileNotFoundError:   \n",
    "        print(\"FILE IS EMPTY, PASSING\")\n",
    "\n",
    "datestamp=datetime.datetime.now().strftime(\"%Y-%m-%d-%H_%M_%S\")\n",
    "\n",
    "outhtml = os.path.join(deriv_path,'bold_motion_QA_%s.html'%(datestamp))\n",
    "out_bad_bold_list = os.path.join(deriv_path,'%s_TEST.txt'%(datestamp))\n",
    "        \n",
    "    # OPEN HTML FILE IF CASE TRUE\n",
    "outfile = open(outhtml, 'a')\n",
    "TITLE=\"\"\"<p><font size=7> <b> Motion Correction Check</b></font><br>\"\"\"\n",
    "outfile.write(\"%s\"%TITLE)\n",
    "\n",
    "\n",
    "    \n",
    "for path in subjects:\n",
    "    sub_id = path.split(\"/\")[-1]\n",
    "    fd_check(sub_id, outfile,\n",
    "             out_bad_bold_list, deriv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_files(filename, moco_df, outputdir):\n",
    "    # iterate through the motion correction data frame by columns, writing individual columns to individual files\n",
    "    for col in moco_df.columns:\n",
    "        file= \"%s_%s.txt\"%(filename, col)\n",
    "        output_path=os.path.join(outputdir, file)\n",
    "        print(\"Writing to file, \", output_path)\n",
    "        moco_df[col].to_csv(output_path, header=False, index=False)\n",
    "\n",
    "\n",
    "def get_motion_parameters(sub):\n",
    "    errors = []\n",
    "    motion_assessment_path =os.path.join( deriv_path, sub, \"func/motion_assessment\" ) \n",
    "    moco_avail = len(glob.glob(os.path.join(motion_assessment_path, \"motion_parameters/*.txt\")))\n",
    "    #print(sub,moco_avail)\n",
    "    if moco_avail < 0:\n",
    "        pass\n",
    "    else:\n",
    "        try:\n",
    "        #print(\"--------------> GETTING MOCOS FOR SUBJECT: \", sub)\n",
    "            outputdir = os.path.join(motion_assessment_path, \"motion_parameters\")\n",
    "            if not os.path.exists(os.path.join(outputdir, 'motion_parameters')):\n",
    "                os.makedirs(os.path.join(outputdir, 'motion_parameters'))\n",
    "        #os.chdir(filepath)\n",
    "            confound_path_s1 = \"/projects/niblab/bids_projects/Experiments/BreakfastClub/fmriprep_lin/fmriprep/%s/ses-1/func/%s_ses-1_task-resting_desc-confounds_regressors.tsv\"%(sub, sub)\n",
    "            confound_path_s2 = \"/projects/niblab/bids_projects/Experiments/BreakfastClub/fmriprep_lin/fmriprep/%s/ses-2/func/%s_ses-2_task-resting_desc-confounds_regressors.tsv\"%(sub, sub)\n",
    "        #print(\"-------> GRABBING FILES:\", confound_path_s1)\n",
    "            df_s1 = pd.read_table(confound_path_s2)\n",
    "            #print(df_s1.columns.values)\n",
    "    # print(df_s1[['motion_outlier01', 'motion_outlier02', 'motion_outlier03', 'motion_outlier04', 'motion_outlier05', 'motion_outlier06']])\n",
    "#        moco_s1=df_s1[['X', 'Y', 'Z', 'RotX', 'RotY', 'RotZ']]\n",
    "            moco_s1= df_s1[['trans_x', 'trans_y', 'trans_z', 'rot_x', 'rot_y', 'rot_z']]\n",
    "            moco_s1.columns = [\"moco0\", \"moco1\", \"moco2\", \"moco3\", \"moco4\", \"moco5\"]\n",
    "            #print(moco_s1)\n",
    "            print(\"DATAFRAME: \\n \", moco_s1.head())\n",
    "            filename = confound_path_s2.split(\"/\")[-1].split(\"_desc-confounds_regressors\")[0]\n",
    "            print(\"FILENAME: \", filename)\n",
    "            write_files(filename, moco_s1, outputdir)\n",
    "        except:\n",
    "            print(\"error subject \", sub)\n",
    "            pass\n",
    "        \"\"\"\n",
    "        #print(\"RUN: \", run)\n",
    "    except FileNotFoundError as not_found:\n",
    "        print(\"********************FILE NOT FOUND: \", not_found.filename)\n",
    "        if sub not in errors:\n",
    "            errors.append(sub)\n",
    "        #print(\"ERRORS \", errors)\n",
    "        #print(\"ERRORS SORTED \", sorted(errors))\n",
    "    errors = sorted(errors)\n",
    "    for err in errors:\n",
    "        #print(\"ERROR\" + err)\n",
    "        file = basedir+\"/error_files_moco.txt\"\n",
    "        with open(file, 'a') as f:\n",
    "            f.write(\"----------> FILE NOT FOUND FOR SUBJECT: \" + err  + \"\\n\")\n",
    "            f.close()\"\"\"\n",
    "        \n",
    "        \n",
    "deriv_path= \"/projects/niblab/bids_projects/Experiments/BreakfastClub/derivatives\"\n",
    "subjects = sorted(glob.glob(os.path.join(deriv_path, \"sub-*\")))\n",
    "\n",
    "    \n",
    "for path in subjects:\n",
    "    sub_id = path.split(\"/\")[-1]\n",
    "    get_motion_parameters(sub_id)\n",
    "    \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
